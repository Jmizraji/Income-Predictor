{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Time to model our data, we're going to be using a lot of different classifiers and trying to find which ones will be the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data with dummies and Lasso CV\n",
    "dummy_income = pd.read_csv('./data/train_modeling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_income = pd.read_csv('./data/train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Features\n",
    "features = dummy_income._get_numeric_data().columns\n",
    "X = dummy_income[features]\n",
    "y = orig_income['wage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['marital-status_Married-civ-spouse', 'education-num', 'capital-gain',\n",
       "       'native-country_United-States', 'occupation_Exec-managerial',\n",
       "       'capital-loss', 'workclass_unknown', 'hours-per-week',\n",
       "       'workclass_Self-emp-not-inc', 'workclass_Private', 'age',\n",
       "       'native-country_Mexico', 'native-country_unknown',\n",
       "       'workclass_Local-gov', 'education_HS-grad', 'occupation_Prof-specialty',\n",
       "       'workclass_State-gov', 'native-country_South',\n",
       "       'occupation_Farming-fishing', 'education_Assoc-acdm', 'sex_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.75919\n",
       "1    0.24081\n",
       "Name: wage, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline model has an accuracy of ~76%, this is our score to beat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_score_classification(X, y, models: list):\n",
    "    # Split data into training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "    \n",
    "    \n",
    "    # Creating empty df to add to later\n",
    "    models_df = pd.DataFrame(columns=['model', \n",
    "                                      'parameters', \n",
    "                                      'train_accuracy',\n",
    "                                      'train_f1',\n",
    "                                      'train_spec',\n",
    "                                      'train_sens',\n",
    "                                      'test_accuracy',\n",
    "                                      'test_f1',\n",
    "                                      'test_spec',\n",
    "                                      'test_sens'])\n",
    "    \n",
    "    for model in models:\n",
    "        # Create a pipeline to scale data and pass through model\n",
    "        pipe = Pipeline([\n",
    "            ('sc', StandardScaler()),\n",
    "            ('model', model) # Thanks Lisa Tagliaferri from Digitalocean.com https://www.digitalocean.com/community/tutorials/how-to-use-args-and-kwargs-in-python-3\n",
    "        ])\n",
    "\n",
    "        # Fitting the model\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_train_preds = pipe.predict(X_train)\n",
    "        y_test_preds = pipe.predict(X_test)\n",
    "        \n",
    "        # Scoring the models\n",
    "        train_score = pipe.score(X_train, y_train)\n",
    "        train_f1 = f1_score(y_train, y_train_preds)\n",
    "        test_score = pipe.score(X_test, y_test)\n",
    "        test_f1 = f1_score(y_test, y_test_preds)\n",
    "        \n",
    "        # Calculate train specificity and sensitivity\n",
    "        tn, fn, fp, tp = confusion_matrix(y_train, pipe.predict(X_train)).ravel()\n",
    "        train_spec = tn / (tn + fp)\n",
    "        train_sens = tp / (tp + fn)\n",
    "        \n",
    "        # Calculate test specificity and sensitivity\n",
    "        tn, fn, fp, tp = confusion_matrix(y_test, pipe.predict(X_test)).ravel()\n",
    "        test_spec = tn / (tn + fp)\n",
    "        test_sens = tp / (tp + fn)\n",
    "        \n",
    "        # Returning a dictionary of the information\n",
    "        model_row = {'model' : type(model).__name__, # Thanks Jonathan from Stack Overflow! https://stackoverflow.com/questions/52763325/how-to-obtain-only-the-name-of-a-models-object-in-scikitlearn\n",
    "                     'parameters' : model.get_params(),\n",
    "                     'train_accuracy' : train_score,\n",
    "                     'train_f1' : train_f1,\n",
    "                     'train_spec' : train_spec,\n",
    "                     'train_sens' : train_sens,\n",
    "                     'test_accuracy': test_score,\n",
    "                     'test_f1': test_f1,\n",
    "                     'test_spec' : test_spec,\n",
    "                     'test_sens' : test_sens}\n",
    "        \n",
    "        # Add new row to models_df\n",
    "        models_df = models_df.append(model_row, ignore_index=True)\n",
    "        \n",
    "        print(f'Done with {model}, moving on')\n",
    "        \n",
    "    return models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_models = [LogisticRegression(n_jobs=12),\n",
    "                        DecisionTreeClassifier(max_depth=6),\n",
    "                        BaggingClassifier(base_estimator = DecisionTreeClassifier(max_depth=6), \n",
    "                                          n_estimators=500, \n",
    "                                          n_jobs=12),\n",
    "                        RandomForestClassifier(max_depth=6, \n",
    "                                               n_estimators=1000, \n",
    "                                               n_jobs=12, \n",
    "                                               random_state=42),\n",
    "                        AdaBoostClassifier(n_estimators=350, \n",
    "                                           random_state=42),\n",
    "                        VotingClassifier([\n",
    "                                        ('logreg', LogisticRegression(n_jobs=12)),\n",
    "                                         ('dt', DecisionTreeClassifier(max_depth=6)),\n",
    "                                         ('bc', BaggingClassifier(base_estimator = DecisionTreeClassifier(max_depth=6), \n",
    "                                                           n_estimators=500, \n",
    "                                                           n_jobs=12)),\n",
    "                                        ('rfc', RandomForestClassifier(max_depth=6, \n",
    "                                                               n_estimators=1000, \n",
    "                                                               n_jobs=12, \n",
    "                                                               random_state=42)),\n",
    "                                        ('ab', AdaBoostClassifier(n_estimators=500, \n",
    "                                                           random_state=42))]),                                        \n",
    "                        SVC(C=10, random_state=42)\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LogisticRegression(n_jobs=12), moving on\n",
      "Done with DecisionTreeClassifier(max_depth=6), moving on\n",
      "Done with BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                  n_estimators=500, n_jobs=12), moving on\n",
      "Done with RandomForestClassifier(max_depth=6, n_estimators=1000, n_jobs=12,\n",
      "                       random_state=42), moving on\n",
      "Done with AdaBoostClassifier(n_estimators=350, random_state=42), moving on\n",
      "Done with VotingClassifier(estimators=[('logreg', LogisticRegression(n_jobs=12)),\n",
      "                             ('dt', DecisionTreeClassifier(max_depth=6)),\n",
      "                             ('bc',\n",
      "                              BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=6),\n",
      "                                                n_estimators=500, n_jobs=12)),\n",
      "                             ('rfc',\n",
      "                              RandomForestClassifier(max_depth=6,\n",
      "                                                     n_estimators=1000,\n",
      "                                                     n_jobs=12,\n",
      "                                                     random_state=42)),\n",
      "                             ('ab',\n",
      "                              AdaBoostClassifier(n_estimators=500,\n",
      "                                                 random_state=42))]), moving on\n",
      "Done with SVC(C=10, random_state=42), moving on\n"
     ]
    }
   ],
   "source": [
    "gen_model_df = model_score_classification(X, y, classification_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_spec</th>\n",
       "      <th>train_sens</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_spec</th>\n",
       "      <th>test_sens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.847625</td>\n",
       "      <td>0.645855</td>\n",
       "      <td>0.874305</td>\n",
       "      <td>0.733463</td>\n",
       "      <td>0.848913</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>0.877305</td>\n",
       "      <td>0.731013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.855405</td>\n",
       "      <td>0.640976</td>\n",
       "      <td>0.866657</td>\n",
       "      <td>0.797167</td>\n",
       "      <td>0.857266</td>\n",
       "      <td>0.649366</td>\n",
       "      <td>0.869751</td>\n",
       "      <td>0.794682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator__ccp_alpha': 0.0, 'base_estim...</td>\n",
       "      <td>0.857494</td>\n",
       "      <td>0.646987</td>\n",
       "      <td>0.868317</td>\n",
       "      <td>0.801861</td>\n",
       "      <td>0.858494</td>\n",
       "      <td>0.654262</td>\n",
       "      <td>0.871473</td>\n",
       "      <td>0.794461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.855201</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>0.857333</td>\n",
       "      <td>0.842136</td>\n",
       "      <td>0.857880</td>\n",
       "      <td>0.631176</td>\n",
       "      <td>0.860712</td>\n",
       "      <td>0.841121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.866544</td>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.885081</td>\n",
       "      <td>0.786245</td>\n",
       "      <td>0.868198</td>\n",
       "      <td>0.696636</td>\n",
       "      <td>0.889092</td>\n",
       "      <td>0.781230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>{'estimators': [('logreg', LogisticRegression(...</td>\n",
       "      <td>0.858518</td>\n",
       "      <td>0.642303</td>\n",
       "      <td>0.865372</td>\n",
       "      <td>0.821069</td>\n",
       "      <td>0.860214</td>\n",
       "      <td>0.650706</td>\n",
       "      <td>0.868479</td>\n",
       "      <td>0.816641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 10, 'break_ties': False, 'cache_size': 2...</td>\n",
       "      <td>0.868018</td>\n",
       "      <td>0.692256</td>\n",
       "      <td>0.886222</td>\n",
       "      <td>0.789416</td>\n",
       "      <td>0.850141</td>\n",
       "      <td>0.650029</td>\n",
       "      <td>0.874981</td>\n",
       "      <td>0.742464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                         parameters  \\\n",
       "0      LogisticRegression  {'C': 1.0, 'class_weight': None, 'dual': False...   \n",
       "1  DecisionTreeClassifier  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "2       BaggingClassifier  {'base_estimator__ccp_alpha': 0.0, 'base_estim...   \n",
       "3  RandomForestClassifier  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "4      AdaBoostClassifier  {'algorithm': 'SAMME.R', 'base_estimator': Non...   \n",
       "5        VotingClassifier  {'estimators': [('logreg', LogisticRegression(...   \n",
       "6                     SVC  {'C': 10, 'break_ties': False, 'cache_size': 2...   \n",
       "\n",
       "   train_accuracy  train_f1  train_spec  train_sens  test_accuracy   test_f1  \\\n",
       "0        0.847625  0.645855    0.874305    0.733463       0.848913  0.652542   \n",
       "1        0.855405  0.640976    0.866657    0.797167       0.857266  0.649366   \n",
       "2        0.857494  0.646987    0.868317    0.801861       0.858494  0.654262   \n",
       "3        0.855201  0.620112    0.857333    0.842136       0.857880  0.631176   \n",
       "4        0.866544  0.688462    0.885081    0.786245       0.868198  0.696636   \n",
       "5        0.858518  0.642303    0.865372    0.821069       0.860214  0.650706   \n",
       "6        0.868018  0.692256    0.886222    0.789416       0.850141  0.650029   \n",
       "\n",
       "   test_spec  test_sens  \n",
       "0   0.877305   0.731013  \n",
       "1   0.869751   0.794682  \n",
       "2   0.871473   0.794461  \n",
       "3   0.860712   0.841121  \n",
       "4   0.889092   0.781230  \n",
       "5   0.868479   0.816641  \n",
       "6   0.874981   0.742464  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like all these models perform fairly well before GridSearching, so let's break these up and use `GridSearchCV` to find the best ones!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearching through `AdaBoostClassifier`, `SVC`, and `GradientNB`\n",
    "\n",
    "Thanks Eric Heidbreder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to split my data!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating AdaBoost Pipeline\n",
    "pipe_ab = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('ab', AdaBoostClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SVC Pipeline\n",
    "pipe_svc = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('svc', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "pipe_gb = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('gb', GaussianNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating GaussianNB params\n",
    "params_gb = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating AdaBoost Params\n",
    "params_ab = {\n",
    "    'ab__n_estimators' : [2500, 3000],\n",
    "    'ab__random_state' : [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SVC Params\n",
    "params_svc = {\n",
    "    'svc__C': [10],\n",
    "    'svc__degree': [2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating AdaBoost GridSearch\n",
    "grid_ab = GridSearchCV(pipe_ab, params_ab, cv=5, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SVC GridSearch\n",
    "grid_svc = GridSearchCV(pipe_svc, params_svc, cv=5, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating GaussianNB GridSearch\n",
    "grid_gb = GridSearchCV(pipe_gb,\n",
    "                     param_grid = params_gb,\n",
    "                     cv = 5,\n",
    "                     verbose = 1,\n",
    "                     scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out so the .csv doesn't get overwritten\n",
    "model_params = {}\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:   45.0s remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   50.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Uncomment if you really want to run this GridSearch again, it will take awhile\n",
    "grid_ab.fit(X_train, y_train)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "# Create a new dictionary entry with the best params used in the GridSearch Pipeline\n",
    "grid_ab.best_params_['best_params'] = grid_ab.best_params_\n",
    "grid_svc.best_params_['best_params'] = grid_svc.best_params_\n",
    "grid_gb.best_params_['best_params'] = grid_gb.best_params_\n",
    "\n",
    "# Create a new dictionary entry with the model used in the GridSearch Pipeline\n",
    "grid_ab.best_params_['model'] = grid_ab.estimator[1]\n",
    "grid_svc.best_params_['model'] = grid_svc.estimator[1]\n",
    "grid_gb.best_params_['model'] = grid_gb.estimator[1]\n",
    "\n",
    "# Create a new dictionary entry with the cv score from the GridSearch\n",
    "grid_ab.best_params_['cv_score'] = grid_ab.best_score_\n",
    "grid_svc.best_params_['cv_score'] = grid_svc.best_score_\n",
    "grid_gb.best_params_['cv_score'] = grid_gb.best_score_\n",
    "\n",
    "# Create a new dictionary entry with the train score from the GridSearch\n",
    "grid_ab.best_params_['train_score'] = grid_ab.score(X_train, y_train)\n",
    "grid_svc.best_params_['train_score'] = grid_svc.score(X_train, y_train)\n",
    "grid_gb.best_params_['train_score'] = grid_gb.score(X_train, y_train)\n",
    "\n",
    "# Create a new dictionary entry with the test score from the GridSearch\n",
    "grid_ab.best_params_['test_score'] = grid_ab.score(X_test, y_test)\n",
    "grid_svc.best_params_['test_score'] = grid_svc.score(X_test, y_test)\n",
    "grid_gb.best_params_['test_score'] = grid_gb.score(X_test, y_test)\n",
    "\n",
    "# Add each of these entries to the list\n",
    "count += 1\n",
    "model_params[f'model_{count}'] = grid_ab.best_params_\n",
    "count += 1\n",
    "model_params[f'model_{count}'] = grid_svc.best_params_\n",
    "count += 1\n",
    "model_params[f'model_{count}'] = grid_gb.best_params_\n",
    "\n",
    "# Create a DataFrame from the dictionary we created above\n",
    "model_df = pd.DataFrame.from_dict(model_params, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab__n_estimators</th>\n",
       "      <th>ab__random_state</th>\n",
       "      <th>best_params</th>\n",
       "      <th>model</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>svc__C</th>\n",
       "      <th>svc__degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>{'ab__n_estimators': 3000, 'ab__random_state':...</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>0.866585</td>\n",
       "      <td>0.868796</td>\n",
       "      <td>0.872620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'svc__C': 10, 'svc__degree': 2, 'best_params'...</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.847830</td>\n",
       "      <td>0.868182</td>\n",
       "      <td>0.852844</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'best_params': {'best_params': {'best_params'...</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.818428</td>\n",
       "      <td>0.819943</td>\n",
       "      <td>0.825574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ab__n_estimators  ab__random_state  \\\n",
       "model_1            3000.0              42.0   \n",
       "model_2               NaN               NaN   \n",
       "model_3               NaN               NaN   \n",
       "\n",
       "                                               best_params  \\\n",
       "model_1  {'ab__n_estimators': 3000, 'ab__random_state':...   \n",
       "model_2  {'svc__C': 10, 'svc__degree': 2, 'best_params'...   \n",
       "model_3  {'best_params': {'best_params': {'best_params'...   \n",
       "\n",
       "                        model  cv_score  train_score  test_score  svc__C  \\\n",
       "model_1  AdaBoostClassifier()  0.866585     0.868796    0.872620     NaN   \n",
       "model_2                 SVC()  0.847830     0.868182    0.852844    10.0   \n",
       "model_3          GaussianNB()  0.818428     0.819943    0.825574     NaN   \n",
       "\n",
       "         svc__degree  \n",
       "model_1          NaN  \n",
       "model_2          2.0  \n",
       "model_3          NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearching through `LogisticRegression`\n",
    "\n",
    "Thanks Irene Anibogwu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8466420966420967\n",
      "Testing Accuracy: 0.8545633214592802\n"
     ]
    }
   ],
   "source": [
    "lr_pipe = Pipeline([ \n",
    "    ('sc', StandardScaler()),\n",
    "    ('lr', LogisticRegression(solver = 'liblinear')),  \n",
    "])\n",
    "\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "\n",
    "print(f'Training Accuracy: {lr_pipe.score(X_train, y_train)}')\n",
    "print(f'Testing Accuracy: {lr_pipe.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearching through `DecisionTreeClassifier` \n",
    "\n",
    "Thanks Irene Anibogwu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 449 out of 480 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search for decision trees to find best estimator and params\n",
    "gridcv = GridSearchCV(estimator = DecisionTreeClassifier(),\n",
    "                    param_grid = {'max_depth': [3, 5, 7, 10],\n",
    "                                  'min_samples_split': [5, 10, 15, 20],\n",
    "                                  'min_samples_leaf': [2, 3, 4, 5, 6, 7]},\n",
    "                    cv = 5,\n",
    "                    verbose = 1,\n",
    "                    n_jobs=-1)\n",
    "gridcv.fit(X_train, y_train)\n",
    "gridcv.best_estimator_\n",
    "gridcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.8572481572481573\n",
      "Score on testing set: 0.8595995577938829\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model w/ best parameters.\n",
    "dt = DecisionTreeClassifier(max_depth = 7,\n",
    "                            min_samples_split = 20,\n",
    "                            min_samples_leaf = 4,\n",
    "                            random_state = 42)\n",
    "# Fit model.\n",
    "dt.fit(X_train, y_train)\n",
    "# Evaluate model.\n",
    "print(f'Score on training set: {dt.score(X_train, y_train)}')\n",
    "print(f'Score on testing set: {dt.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearching through `RandomForestClassifier`\n",
    "\n",
    "Thanks Josh Mizraji!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {}\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>55</td>\n",
       "      <td>0.857985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         max_depth max_features  n_estimators     score\n",
       "model_1          9         None            55  0.857985"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaffolding\n",
    "params_rf = {\n",
    "    'n_estimators' : [55,60,70], #number of trees\n",
    "    'max_features' : [None], \n",
    "    'max_depth' : [7,8,9]\n",
    "}\n",
    "#Instantiate Gridsearch\n",
    "gs_rf = GridSearchCV(RandomForestClassifier(), \n",
    "                 param_grid=params_rf,\n",
    "                 cv=5,\n",
    "                n_jobs=-1)\n",
    "#Fit\n",
    "gs_rf.fit(X_train, y_train)\n",
    "#this takes the best params dictionary and adds a column called score\n",
    "gs_rf.best_params_['score'] = gs_rf.best_score_\n",
    "#make a counter\n",
    "count +=1\n",
    "#create new column with best params\n",
    "model_params[f'model_{count}'] = gs_rf.best_params_\n",
    "#orient sideways\n",
    "model_df = pd.DataFrame.from_dict(model_params, orient='index')\n",
    "model_df\n",
    "#adapted from DSI lesson "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearching through `BaggingClassifier`\n",
    "\n",
    "Thanks Juhee Sung-Schenck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8540540540540541\n",
      "TestingScore: 0.8578798673381648\n"
     ]
    }
   ],
   "source": [
    "# Building pipeline for BaggingClassifier\n",
    "pipe_bag = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('bag', BaggingClassifier(base_estimator = DecisionTreeClassifier(max_depth = 6)))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'bag__n_estimators': [1000],\n",
    "    'bag__max_samples': [300],\n",
    "    'bag__max_features': [18]\n",
    "}\n",
    "\n",
    "gs_bag = GridSearchCV(pipe_bag,\n",
    "                      param_grid = params,\n",
    "                      cv = 3,\n",
    "                      verbose = 1,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "# fit\n",
    "gs_bag.fit(X_train, y_train)\n",
    "\n",
    "# score\n",
    "print(f'Training Score: {gs_bag.score(X_train, y_train)}')\n",
    "print(f'TestingScore: {gs_bag.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running `VotingClassifier` on our best models as determined by `GridSearchCV`\n",
    "\n",
    "Thanks Eric Heidbreder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = VotingClassifier([\n",
    "    ('ab', AdaBoostClassifier(n_estimators=2500, random_state=42)),\n",
    "    ('bag', BaggingClassifier(n_estimators=2000,\n",
    "                             max_samples=300,\n",
    "                             max_features=len(features))),\n",
    "    ('rf', RandomForestClassifier(max_depth=9,\n",
    "                                 n_estimators=70)),\n",
    "    ('dt', DecisionTreeClassifier(max_depth = 7,\n",
    "                                  min_samples_split = 20,\n",
    "                                  min_samples_leaf = 4,\n",
    "                                  random_state = 42)),\n",
    "], n_jobs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('ab',\n",
       "                              AdaBoostClassifier(n_estimators=2500,\n",
       "                                                 random_state=42)),\n",
       "                             ('bag',\n",
       "                              BaggingClassifier(max_features=21,\n",
       "                                                max_samples=300,\n",
       "                                                n_estimators=2000)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(max_depth=9,\n",
       "                                                     n_estimators=70)),\n",
       "                             ('dt',\n",
       "                              DecisionTreeClassifier(max_depth=7,\n",
       "                                                     min_samples_leaf=4,\n",
       "                                                     min_samples_split=20,\n",
       "                                                     random_state=42))],\n",
       "                 n_jobs=12)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.864004914004914"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Score\n",
    "vc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8638987839331778"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Score\n",
    "vc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in test data\n",
    "income_test = pd.read_csv('./data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the ? with 'unknown'\n",
    "income_test.replace(' ?', \"unknown\", inplace = True )\n",
    "cat_columns_test = income_test.drop(columns = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], axis = 1).columns\n",
    "\n",
    "# Stripping whitespace from beginning of each value\n",
    "for column in cat_columns_test:\n",
    "    income_test[column] = income_test[column].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize the `sex` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_test['sex'] = np.where(income_test['sex'] == 'Male', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting `fnlwgt` to a sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sample weight column, thanks Eric Heidbreder!\n",
    "income_test['smpl_wgt'] = income_test['fnlwgt'].apply(lambda x: x / income_test['fnlwgt'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested the sample weight out with our models later, and it wasn't very good, so we abandoned this column eventually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating log_age column\n",
    "\n",
    "Age benefited from a log transform, which converted it to a more normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log age, thanks Eric Heidbreder!\n",
    "income_test['log_age'] = np.log(income_test['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummifying Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummifying Features, thanks Juhee Sung-Schenck!\n",
    "income_test_d = pd.get_dummies(columns = ['workclass', 'education', 'marital-status', 'occupation', 'sex', 'native-country'], data=income_test, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting predictions for Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Features\n",
    "features = [column for column in dummy_income.columns if column in income_test_d.columns] # Selects only the columns that are in income_test\n",
    "X = dummy_income[features]\n",
    "y = orig_income['wage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = AdaBoostClassifier(n_estimators=2500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=2500, random_state=42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab.fit(X, y) # Training the model on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ab.predict(income_test_d[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16281,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds, columns=['wage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_csv('./data/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
